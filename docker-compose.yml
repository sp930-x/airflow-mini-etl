services:
  postgres:
    image: postgres:15
    container_name: weather_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 10

  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.8.2
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./:/opt/project
    working_dir: /opt/project
    environment:
      DBT_PROFILES_DIR: /opt/project/.dbt
    command: ["dbt"]

  airflow-webserver:
    image: apache/airflow:2.9.3
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/project/dags
      AIRFLOW_UID: "50000"
      PYTHONPATH: /opt/airflow/project
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      HOST_PROJECT_DIR: ${HOST_PROJECT_DIR}

      # For Python ETL (etl/load.py)
      PGHOST: ${PGHOST}
      PGPORT: ${PGPORT}
      PGDATABASE: ${PGDATABASE}
      PGUSER: ${PGUSER}
      PGPASSWORD: ${PGPASSWORD}

      # Bootstrap Airflow connection "postgres_default"
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_CONN_POSTGRES_DEFAULT}

    volumes:
      - ./:/opt/airflow/project
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /opt/airflow/project
    ports:
      - "8080:8080"
    command: >
      bash -lc "
      pip install --no-cache-dir psycopg2-binary apache-airflow-providers-docker docker &&
      airflow db init &&
      airflow users create
        --username ${AIRFLOW_ADMIN_USER}
        --password ${AIRFLOW_ADMIN_PASSWORD}
        --firstname Admin
        --lastname User
        --role Admin
        --email admin@example.com || true &&
      airflow webserver
      "

  airflow-scheduler:
    image: apache/airflow:2.9.3
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/project/dags
      AIRFLOW_UID: "50000"
      PYTHONPATH: /opt/airflow/project
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
      HOST_PROJECT_DIR: ${HOST_PROJECT_DIR}

      # For Python ETL (etl/load.py)
      PGHOST: ${PGHOST}
      PGPORT: ${PGPORT}
      PGDATABASE: ${PGDATABASE}
      PGUSER: ${PGUSER}
      PGPASSWORD: ${PGPASSWORD}

      # Bootstrap Airflow connection "postgres_default"
      AIRFLOW_CONN_POSTGRES_DEFAULT: ${AIRFLOW_CONN_POSTGRES_DEFAULT}

    volumes:
      - ./:/opt/airflow/project
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /opt/airflow/project
    command: >
      bash -lc "
      pip install --no-cache-dir psycopg2-binary apache-airflow-providers-docker docker &&
      airflow db check &&
      airflow scheduler
      "

volumes:
  postgres-db-volume: