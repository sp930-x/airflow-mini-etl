# âš¡ Airflow Mini ETL Project: Weather-Driven Energy Demand Pipeline

> Containerized data engineering pipeline modeling temperature-driven regional energy demand with reproducible SQL analytics and performance-aware schema design.

---

## ğŸš€ Overview

**Goal**  
Build a containerized, production-like ETL pipeline that transforms hourly weather data into daily, analytics-ready energy aggregates.

**Stack**  
Airflow Â· PostgreSQL Â· Docker Â· Python

**Key Highlights**
- Layered warehouse design (`raw â†’ staging â†’ mart`)
- Idempotent UPSERT with composite PK `(ts, region)`
- SQL-based data quality checks
- Composite index `(region, ts)` validated via `EXPLAIN`
- Reproducible business insights (`analysis_business.sql`)

---

## ğŸ³ Architecture

### Why Docker?

- Reproducible environment
- Service isolation (Airflow + PostgreSQL)
- Production-like orchestration
- One-command startup

![Architecture](https://github.com/user-attachments/assets/a36995d4-869c-4f00-9113-2869acb35501)

## ğŸ— Orchestration

![Airflow DAG Success Flow](https://github.com/user-attachments/assets/6b2d58d8-a6f4-4aad-bab3-72baf7b6e0e5)

Main DAG: `weather_energy_daily_mart`

Pipeline steps:
1. Extract weather data
2. Generate synthetic energy load
3. Load â†’ raw
4. Transform â†’ staging
5. Aggregate â†’ mart
6. Execute data quality checks

All tasks are idempotent and dependency-aware.

---

## ğŸ“Š Data Model

| Layer   | Purpose |
|----------|----------|
| `raw`    | Source traceability |
| `staging`| Standardized hourly data |
| `mart`   | Daily aggregated fact table |

Fact table: `mart.fact_energy_load_daily`


---

## ğŸ›¡ Data Quality

Automated SQL checks for:
- Duplicate & grain validation
- NULL enforcement
- Temperature sanity range
- Hour-over-hour anomaly detection
- Row-count drift monitoring

---

## âš¡ Performance

- Composite index on `(region, ts)`
- No sequential scans on time-window joins
- Execution time: ~0.7â€“1.4 ms

---

## ğŸ§  Business Insights

Derived via `sql/analysis_business.sql`.

- **Cold-shock events:** None observed (â‰¤ -5Â°C hourly drop, n=0)
- **Peak demand hour:** 06:00 (across 3/3 regions)
- **Weekend effect:** -142.5 MW (~ -10.9%) vs weekdays

---

## ğŸ“ Structure

```
airflow-mini-etl/
â”œâ”€â”€ dags/
â”œâ”€â”€ etl/
â”œâ”€â”€ sql/
â”œâ”€â”€ docs/
â”œâ”€â”€ data/
â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ Quickstart

Start services:

        docker compose up -d

Access Airflow:  
http://localhost:8080  
(admin / admin)

Trigger DAG:  
`weather_energy_daily_mart`

Run analysis:

        cat sql/analysis_business.sql | docker exec -i weather_postgres psql -U airflow -d airflow

(Windows PowerShell)

        Get-Content sql/analysis_business.sql | docker exec -i weather_postgres psql -U airflow -d airflow

Reproducibility check:
- staging.energy_hourly_clean rowcount: 2160
- mart.fact_energy_load_daily rowcount: 90
- analysis output is stable across re-runs (rounded outputs in sql/analysis_business.sql)


---

## ğŸ¯ Focus

This project emphasizes:
- Data pipeline architecture
- SQL-driven analytical reproducibility
- Performance-aware schema design
- Containerized deployment
